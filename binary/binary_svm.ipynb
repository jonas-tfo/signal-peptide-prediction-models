{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db292da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import tqdm as notebook_tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "MODEL_NAME = \"Rostlab/prot_bert\" \n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cpu\" # using mps instead of cuda for training on mac\n",
    "#DEVICE = \"cpu\"  # use GPU if available, otherwise CPU\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "NUM_CLASSES = 6  # num classes for classification\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f325b23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 25693\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "uniprot_ac",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "kingdom",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sequence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "79bbbb7b-087e-4ea6-b8d1-b8cce1884e2d",
       "rows": [
        [
         "0",
         "Q8TF40",
         "EUKARYA",
         "NO_SP",
         "MAPTLFQKLFSKRTGLGAPGRDARDPDCGFSWPLPEFDPSQIRLIVYQDCERRGRNVLFDSSVKRRNEDI",
         "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII"
        ],
        [
         "1",
         "Q1ENB6",
         "EUKARYA",
         "NO_SP",
         "MDFTSLETTTFEEVVIALGSNVGNRMNNFKEALRLMKDYGISVTRHSCLYETEPVHVTDQPRFLNAAIRG",
         "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII"
        ],
        [
         "2",
         "P36001",
         "EUKARYA",
         "NO_SP",
         "MDDISGRQTLPRINRLLEHVGNPQDSLSILHIAGTNGKETVSKFLTSILQHPGQQRQRVLIGRYTTSSLL",
         "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII"
        ],
        [
         "3",
         "P55317",
         "EUKARYA",
         "NO_SP",
         "MLGTVKMEGHETSDWNSYYADTQEAYSSVPVSNMNSGLGSMNSMNTYMTMNTMTTSGNMTPASFNMSYAN",
         "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII"
        ],
        [
         "4",
         "P35583",
         "EUKARYA",
         "NO_SP",
         "MLGAVKMEGHEPSDWSSYYAEPEGYSSVSNMNAGLGMNGMNTYMSMSAAAMGGGSGNMSAGSMNMSSYVG",
         "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_ac</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>type</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q8TF40</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>MAPTLFQKLFSKRTGLGAPGRDARDPDCGFSWPLPEFDPSQIRLIV...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1ENB6</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>MDFTSLETTTFEEVVIALGSNVGNRMNNFKEALRLMKDYGISVTRH...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P36001</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>MDDISGRQTLPRINRLLEHVGNPQDSLSILHIAGTNGKETVSKFLT...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P55317</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>MLGTVKMEGHETSDWNSYYADTQEAYSSVPVSNMNSGLGSMNSMNT...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P35583</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>MLGAVKMEGHEPSDWSSYYAEPEGYSSVSNMNAGLGMNGMNTYMSM...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uniprot_ac  kingdom   type  \\\n",
       "0     Q8TF40  EUKARYA  NO_SP   \n",
       "1     Q1ENB6  EUKARYA  NO_SP   \n",
       "2     P36001  EUKARYA  NO_SP   \n",
       "3     P55317  EUKARYA  NO_SP   \n",
       "4     P35583  EUKARYA  NO_SP   \n",
       "\n",
       "                                            sequence  \\\n",
       "0  MAPTLFQKLFSKRTGLGAPGRDARDPDCGFSWPLPEFDPSQIRLIV...   \n",
       "1  MDFTSLETTTFEEVVIALGSNVGNRMNNFKEALRLMKDYGISVTRH...   \n",
       "2  MDDISGRQTLPRINRLLEHVGNPQDSLSILHIAGTNGKETVSKFLT...   \n",
       "3  MLGTVKMEGHETSDWNSYYADTQEAYSSVPVSNMNSGLGSMNSMNT...   \n",
       "4  MLGAVKMEGHEPSDWSSYYAEPEGYSSVSNMNAGLGMNGMNTYMSM...   \n",
       "\n",
       "                                               label  \n",
       "0  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...  \n",
       "1  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...  \n",
       "2  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...  \n",
       "3  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...  \n",
       "4  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "records = []  # uniprot_ac, kingdom, type_, sequence, label\n",
    "with open(\"/Users/jonas/Desktop/Uni/PBL/data/complete_set_unpartitioned.fasta\", \"r\") as f:\n",
    "    current_record = None\n",
    "    for line in f:\n",
    "        if line.startswith(\">\"):\n",
    "            if current_record is not None:\n",
    "                if current_record[\"sequence\"] is not None and current_record[\"label\"] is not None:\n",
    "                    # Save the previous record before starting a new one\n",
    "                    records.append(current_record)\n",
    "                else:\n",
    "                    # If the previous record is incomplete, skip it\n",
    "                    print(\"Skipping incomplete record:\", current_record)\n",
    "            # Start a new record\n",
    "            uniprot_ac, kingdom, type_ = line[1:].strip().split(\"|\")\n",
    "            current_record = {\"uniprot_ac\": uniprot_ac, \"kingdom\": kingdom, \"type\": type_, \"sequence\": None, \"label\": None}\n",
    "        else:\n",
    "            # Check if the line contains a sequence or a label\n",
    "            if current_record[\"sequence\"] is None:\n",
    "                current_record[\"sequence\"] = line.strip()\n",
    "            elif current_record[\"label\"] is None:\n",
    "                current_record[\"label\"] = line.strip()\n",
    "            else:\n",
    "                # If both sequence and label are already set, skip this line\n",
    "                print(\"Skipping extra line in record:\", current_record)\n",
    "    # Save the last record if it's complete\n",
    "    if current_record is not None:\n",
    "        if current_record[\"sequence\"] is not None and current_record[\"label\"] is not None:\n",
    "            records.append(current_record)\n",
    "        else:\n",
    "            print(\"Skipping incomplete record:\", current_record)\n",
    "\n",
    "\"\"\"\n",
    "# Save the DataFrame to a CSV file\n",
    "df_raw.to_csv(\"/Users/jonas/Desktop/Uni/PBL/data/complete_set_unpartitioned.csv\", index=False)\n",
    "\"\"\"\n",
    "# Print the number of records\n",
    "print(f\"Total records: {len(records)}\")\n",
    "df_raw = pd.DataFrame(records)\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f42d71bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25580 entries, 0 to 25692\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   uniprot_ac  25580 non-null  object\n",
      " 1   kingdom     25580 non-null  object\n",
      " 2   type        25580 non-null  int64 \n",
      " 3   sequence    25580 non-null  object\n",
      " 4   label       25580 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ld/_1vh76bj5597tgzpl600cczc0000gn/T/ipykernel_33864/113883726.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"type\"] = df[\"type\"].replace(\"NO_SP\", 0)\n",
      "/var/folders/ld/_1vh76bj5597tgzpl600cczc0000gn/T/ipykernel_33864/113883726.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"type\"] = df[\"type\"].replace(\"SP\", 1)\n",
      "/var/folders/ld/_1vh76bj5597tgzpl600cczc0000gn/T/ipykernel_33864/113883726.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"type\"] = df[\"type\"].replace(\"LIPO\", 1)\n",
      "/var/folders/ld/_1vh76bj5597tgzpl600cczc0000gn/T/ipykernel_33864/113883726.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"type\"] = df[\"type\"].replace(\"TAT\", 1)\n",
      "/var/folders/ld/_1vh76bj5597tgzpl600cczc0000gn/T/ipykernel_33864/113883726.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"type\"] = df[\"type\"].replace(\"TATLIPO\", 1)\n",
      "/var/folders/ld/_1vh76bj5597tgzpl600cczc0000gn/T/ipykernel_33864/113883726.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"type\"] = df[\"type\"].replace(\"TATLIPO\", 1)\n"
     ]
    }
   ],
   "source": [
    "df = df_raw[~df_raw[\"label\"].str.contains(\"P\")]\n",
    "\n",
    "df[\"type\"] = df[\"type\"].replace(\"NO_SP\", 0)\n",
    "df[\"type\"] = df[\"type\"].replace(\"SP\", 1)\n",
    "df[\"type\"] = df[\"type\"].replace(\"LIPO\", 1)\n",
    "df[\"type\"] = df[\"type\"].replace(\"TAT\", 1)\n",
    "df[\"type\"] = df[\"type\"].replace(\"TATLIPO\", 1)\n",
    "\n",
    "# print all unique types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f97bca8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "uniprot_ac",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "kingdom",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "type",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sequence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "aaa916cb-6700-425a-9b85-4ee79bd99100",
       "rows": [
        [
         "0",
         "Q8TF40",
         "EUKARYA",
         "0",
         "MAPTLFQKLFSKRTGLGAPGRDARDPDCGFSWPLPEFDPSQIRLIVYQDCERRGRNVLFDSSVKRRNEDI",
         "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
        ],
        [
         "1",
         "Q1ENB6",
         "EUKARYA",
         "0",
         "MDFTSLETTTFEEVVIALGSNVGNRMNNFKEALRLMKDYGISVTRHSCLYETEPVHVTDQPRFLNAAIRG",
         "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
        ],
        [
         "2",
         "P36001",
         "EUKARYA",
         "0",
         "MDDISGRQTLPRINRLLEHVGNPQDSLSILHIAGTNGKETVSKFLTSILQHPGQQRQRVLIGRYTTSSLL",
         "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
        ],
        [
         "3",
         "P55317",
         "EUKARYA",
         "0",
         "MLGTVKMEGHETSDWNSYYADTQEAYSSVPVSNMNSGLGSMNSMNTYMTMNTMTTSGNMTPASFNMSYAN",
         "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
        ],
        [
         "4",
         "P35583",
         "EUKARYA",
         "0",
         "MLGAVKMEGHEPSDWSSYYAEPEGYSSVSNMNAGLGMNGMNTYMSMSAAAMGGGSGNMSAGSMNMSSYVG",
         "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_ac</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>type</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q8TF40</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>0</td>\n",
       "      <td>MAPTLFQKLFSKRTGLGAPGRDARDPDCGFSWPLPEFDPSQIRLIV...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1ENB6</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>0</td>\n",
       "      <td>MDFTSLETTTFEEVVIALGSNVGNRMNNFKEALRLMKDYGISVTRH...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P36001</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>0</td>\n",
       "      <td>MDDISGRQTLPRINRLLEHVGNPQDSLSILHIAGTNGKETVSKFLT...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P55317</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>0</td>\n",
       "      <td>MLGTVKMEGHETSDWNSYYADTQEAYSSVPVSNMNSGLGSMNSMNT...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P35583</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>0</td>\n",
       "      <td>MLGAVKMEGHEPSDWSSYYAEPEGYSSVSNMNAGLGMNGMNTYMSM...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uniprot_ac  kingdom  type  \\\n",
       "0     Q8TF40  EUKARYA     0   \n",
       "1     Q1ENB6  EUKARYA     0   \n",
       "2     P36001  EUKARYA     0   \n",
       "3     P55317  EUKARYA     0   \n",
       "4     P35583  EUKARYA     0   \n",
       "\n",
       "                                            sequence  \\\n",
       "0  MAPTLFQKLFSKRTGLGAPGRDARDPDCGFSWPLPEFDPSQIRLIV...   \n",
       "1  MDFTSLETTTFEEVVIALGSNVGNRMNNFKEALRLMKDYGISVTRH...   \n",
       "2  MDDISGRQTLPRINRLLEHVGNPQDSLSILHIAGTNGKETVSKFLT...   \n",
       "3  MLGTVKMEGHETSDWNSYYADTQEAYSSVPVSNMNSGLGSMNSMNT...   \n",
       "4  MLGAVKMEGHEPSDWSSYYAEPEGYSSVSNMNAGLGMNGMNTYMSM...   \n",
       "\n",
       "                                               label  \n",
       "0  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
       "1  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
       "2  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
       "3  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
       "4  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {'S': 0, 'T': 1, 'L': 2, 'I': 3, 'M': 4, 'O': 5}\n",
    "\n",
    "df_encoded = df.copy()\n",
    "df_encoded[\"label\"] = df_encoded[\"label\"].apply(lambda x: [label_map[c] for c in x if c in label_map])\n",
    "df_encoded = df_encoded[df_encoded[\"label\"].map(len) > 0]  # Remove rows with empty label lists\n",
    "\n",
    "df_encoded.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b00a2650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type distribution after balancing:\n",
      "type\n",
      "1    19036\n",
      "0    19036\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# perform oversampling of class 1 to balance the dataset\n",
    "from sklearn.utils import resample\n",
    "# Separate majority and minority classes\n",
    "df_majority = df_encoded[df_encoded[\"type\"] == 0]\n",
    "df_minority = df_encoded[df_encoded[\"type\"] == 1]\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                  replace=True,     # sample with replacement\n",
    "                                  n_samples=len(df_majority),    # to match majority class\n",
    "                                  random_state=42) # reproducible results\n",
    "# Combine majority class with upsampled minority class\n",
    "df_balanced = pd.concat([df_majority, df_minority_upsampled])\n",
    "# Shuffle the dataset\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "sequences = df_balanced[\"sequence\"].tolist()\n",
    "label_seqs = df_balanced[\"label\"].tolist()\n",
    "types = df_balanced[\"type\"].tolist()\n",
    "\n",
    "# print frequency of each type\n",
    "print(\"Type distribution after balancing:\")\n",
    "print(df_balanced[\"type\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "58190cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(40000, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-29): 30 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=False)\n",
    "encoder = BertModel.from_pretrained(MODEL_NAME)\n",
    "encoder.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "253c77e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating BERT embeddings...\n",
      "Shape of X: (38072, 1024)\n",
      "Shape of y: (38072,)\n",
      "\n",
      "--- Training Model with scale_pos_weight ---\n",
      "\n",
      "--- Model Performance with Adjusted Threshold (0.10) ---\n",
      "Accuracy: 0.50\n",
      "Precision: 0.50\n",
      "Recall: 1.00\n",
      "F1-Score: 0.67\n",
      "Distribution of adjusted predictions: Counter({1: 7615})\n",
      "\n",
      "--- Model Performance with Adjusted Threshold (0.20) ---\n",
      "Accuracy: 0.50\n",
      "Precision: 0.50\n",
      "Recall: 1.00\n",
      "F1-Score: 0.67\n",
      "Distribution of adjusted predictions: Counter({1: 7615})\n",
      "\n",
      "--- Model Performance with Adjusted Threshold (0.30) ---\n",
      "Accuracy: 0.50\n",
      "Precision: 0.50\n",
      "Recall: 1.00\n",
      "F1-Score: 0.67\n",
      "Distribution of adjusted predictions: Counter({1: 7615})\n",
      "\n",
      "--- Model Performance with Adjusted Threshold (0.40) ---\n",
      "Accuracy: 0.50\n",
      "Precision: 0.50\n",
      "Recall: 1.00\n",
      "F1-Score: 0.67\n",
      "Distribution of adjusted predictions: Counter({1: 7615})\n",
      "\n",
      "--- Model Performance with Adjusted Threshold (0.50) ---\n",
      "Accuracy: 0.50\n",
      "Precision: 0.50\n",
      "Recall: 1.00\n",
      "F1-Score: 0.67\n",
      "Distribution of adjusted predictions: Counter({1: 7615})\n",
      "\n",
      "--- Model Performance with Adjusted Threshold (0.60) ---\n",
      "Accuracy: 0.50\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-Score: 0.00\n",
      "Distribution of adjusted predictions: Counter({0: 7615})\n",
      "\n",
      "--- Model Performance with Adjusted Threshold (0.70) ---\n",
      "Accuracy: 0.50\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-Score: 0.00\n",
      "Distribution of adjusted predictions: Counter({0: 7615})\n",
      "\n",
      "--- Model Performance with Adjusted Threshold (0.80) ---\n",
      "Accuracy: 0.50\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-Score: 0.00\n",
      "Distribution of adjusted predictions: Counter({0: 7615})\n",
      "\n",
      "--- Model Performance with Adjusted Threshold (0.90) ---\n",
      "Accuracy: 0.50\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-Score: 0.00\n",
      "Distribution of adjusted predictions: Counter({0: 7615})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to get BERT embeddings for a given text and return mean-pooled embeddings\n",
    "# Function to get BERT embeddings\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = encoder(**inputs)\n",
    "    attention_mask = inputs[\"attention_mask\"].unsqueeze(-1)\n",
    "    token_embeddings = outputs.last_hidden_state\n",
    "    sum_embeddings = (token_embeddings * attention_mask).sum(1)\n",
    "    sum_mask = attention_mask.sum(1)\n",
    "    mean_pooled = sum_embeddings / sum_mask\n",
    "    return mean_pooled.cpu().numpy().flatten()\n",
    "\n",
    "print(\"Generating BERT embeddings...\")\n",
    "# Extract features from all sequences using the encoder\n",
    "# This can be slow for large datasets; consider batch processing for efficiency\n",
    "embeddings = np.array([get_bert_embedding(seq) for seq in sequences])\n",
    "y = np.array(types)\n",
    "print(f\"Shape of X: {embeddings.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "\n",
    "# Split the dataset into training and testing subsets\n",
    "embeddings_train, embeddings_test, y_train, y_test = train_test_split(embeddings, y, test_size=0.2, random_state=42, stratify=y) \n",
    "\n",
    "# Initial model evaluation (your original code snippet)\n",
    "model_scaled = XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(\"\\n--- Training Model with scale_pos_weight ---\")\n",
    "model_scaled.fit(embeddings_train, y_train)\n",
    "\n",
    "y_pred_proba = model_scaled.predict_proba(embeddings_test)[:, 1]\n",
    "\n",
    "# Try different thresholds:\n",
    "thresholds_to_test = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] # Add more granular steps if needed\n",
    "\n",
    "for threshold in thresholds_to_test:\n",
    "    y_pred_adjusted = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "    accuracy_adjusted = accuracy_score(y_test, y_pred_adjusted)\n",
    "    precision_adjusted, recall_adjusted, f1_adjusted, _ = precision_recall_fscore_support(\n",
    "        y_test, y_pred_adjusted, average='binary', zero_division=0\n",
    "    )\n",
    "\n",
    "    print(f\"\\n--- Model Performance with Adjusted Threshold ({threshold:.2f}) ---\")\n",
    "    print(f\"Accuracy: {accuracy_adjusted:.2f}\")\n",
    "    print(f\"Precision: {precision_adjusted:.2f}\")\n",
    "    print(f\"Recall: {recall_adjusted:.2f}\")\n",
    "    print(f\"F1-Score: {f1_adjusted:.2f}\")\n",
    "    print(f\"Distribution of adjusted predictions: {Counter(y_pred_adjusted)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
